{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOjn7C7xkD67DJHaVvCeGxs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import cv2\n","import torch\n","import cv2\n","import os\n","from pathlib import Path\n","from IPython.display import display, Image as IPImage, HTML\n","from PIL import Image\n","import base64"],"metadata":{"id":"Kzt0_SrUrqGj","executionInfo":{"status":"ok","timestamp":1752749990304,"user_tz":-60,"elapsed":5739,"user":{"displayName":"MHM Rajpoot","userId":"04803560733234745493"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dpZnN4zzqSyk","outputId":"7c5506c7-00e3-4fcf-cb60-67570268422e"},"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch version: 2.6.0+cu124\n","Torchvision version: 0.21.0+cu124\n","CUDA is available: True\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Collecting git+https://github.com/facebookresearch/sam2.git\n","  Cloning https://github.com/facebookresearch/sam2.git to /tmp/pip-req-build-mlchzx_b\n","  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/sam2.git /tmp/pip-req-build-mlchzx_b\n","  Resolved https://github.com/facebookresearch/sam2.git to commit 2b90b9f5ceec907a1c18123530e92e794ad901a4\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.6.0+cu124)\n","Requirement already satisfied: torchvision>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (0.21.0+cu124)\n","Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.0.2)\n","Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (4.67.1)\n","Requirement already satisfied: hydra-core>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (1.3.2)\n","Requirement already satisfied: iopath>=0.1.10 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (0.1.10)\n","Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (11.2.1)\n","Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (2.3.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (4.9.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (24.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.10->SAM-2==1.0) (4.14.1)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.10->SAM-2==1.0) (3.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.5.1->SAM-2==1.0) (1.3.0)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4,>=2.2->hydra-core>=1.3.2->SAM-2==1.0) (6.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.1->SAM-2==1.0) (3.0.2)\n","--2025-07-17 11:02:01--  https://dl.fbaipublicfiles.com/segment_anything_2/assets/bedroom.zip\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.169.202.3, 3.169.202.78, 3.169.202.87, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.169.202.3|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 12688166 (12M) [application/zip]\n","Saving to: ‘videos/bedroom.zip.1’\n","\n","bedroom.zip.1       100%[===================>]  12.10M  64.8MB/s    in 0.2s    \n","\n","2025-07-17 11:02:02 (64.8 MB/s) - ‘videos/bedroom.zip.1’ saved [12688166/12688166]\n","\n","Archive:  videos/bedroom.zip\n","replace videos/bedroom/00005.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "]}],"source":["using_colab = True\n","\n","if using_colab:\n","\n","    import torch\n","    import torchvision\n","\n","    print(\"PyTorch version:\", torch.__version__)\n","    print(\"Torchvision version:\", torchvision.__version__)\n","    print(\"CUDA is available:\", torch.cuda.is_available())\n","\n","    import sys\n","\n","    !{sys.executable} -m pip install opencv-python matplotlib\n","    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/sam2.git'\n","\n","    !mkdir -p videos\n","    !wget -P videos https://dl.fbaipublicfiles.com/segment_anything_2/assets/bedroom.zip\n","    !unzip -d videos videos/bedroom.zip\n","\n","    !mkdir -p ../checkpoints/\n","    !wget -P ../checkpoints/ https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt"]},{"cell_type":"code","source":["!git clone https://github.com/ultralytics/yolov5\n","\n","%cd yolov5\n","\n","!pip install -r requirements.txt"],"metadata":{"id":"OG8K5lQKuxLL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Folder path\n","folder_path = \"/content/videos/bedroom\"\n","output_gif_path = \"/content/videos/bedroom.gif\"\n","duration = 100  # Duration per frame in milliseconds\n","\n","# Get sorted image files\n","image_files = sorted([f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp'))])\n","\n","# Create full paths and open images\n","frames = []\n","for image_file in image_files:\n","\n","    image_path = os.path.join(folder_path, image_file)\n","    img = Image.open(image_path).convert('RGB')\n","    frames.append(img)\n","\n","# Save as GIF\n","if frames:\n","    frames[0].save(\n","        output_gif_path,\n","        format='GIF',\n","        append_images=frames[1:],\n","        save_all=True,\n","        duration=duration,\n","        loop=0\n","    )\n","    print(f\"GIF saved at: {output_gif_path}\")\n","else:\n","    print(\"No images to convert.\")\n"],"metadata":{"id":"zbnS9mjlq1Dk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Read GIF and convert to base64\n","with open(output_gif_path, \"rb\") as gif_file:\n","    gif_base64 = base64.b64encode(gif_file.read()).decode(\"utf-8\")\n","\n","# Embed in HTML\n","html_code = f'''\n","<h3>Generated GIF:</h3>\n","<img src=\"data:image/gif;base64,{gif_base64}\" alt=\"Generated GIF\">\n","'''\n","\n","# Display HTML\n","display(HTML(html_code))"],"metadata":{"id":"JN_RBv8utNTr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load YOLOv5 model (pretrained on COCO)\n","model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n","\n","# Folder of images\n","folder_path = \"/content/videos/bedroom\"\n","output_path = \"/content/videos/yolo_output\"\n","os.makedirs(output_path, exist_ok=True)\n","\n","# Get sorted image files\n","image_files = sorted([f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp'))])\n","\n","# Loop through and detect objects\n","for image_file in image_files:\n","    image_path = os.path.join(folder_path, image_file)\n","    results = model(image_path)\n","\n","    # Plot and save results\n","    results.render()  # Draw bounding boxes on the image\n","    result_img = results.ims[0]  # Image with boxes\n","\n","    # Save the result image\n","    out_image_path = os.path.join(output_path, image_file)\n","    cv2.imwrite(out_image_path, result_img[:, :, ::-1])  # Convert RGB to BGR for OpenCV\n","\n","print(\"YOLO detection complete. Output saved to:\", output_path)\n"],"metadata":{"id":"H5I9G3cMuMzG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output_gif_path = \"/content/videos/yolo_detected.gif\"\n","image_files = sorted([f for f in os.listdir(output_path) if f.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp'))])\n","frames = [Image.open(os.path.join(output_path, f)).convert(\"RGB\") for f in image_files]\n","\n","if frames:\n","    frames[0].save(\n","        output_gif_path,\n","        format='GIF',\n","        append_images=frames[1:],\n","        save_all=True,\n","        duration=100,\n","        loop=0\n","    )\n","    print(\"YOLO detection GIF saved at:\", output_gif_path)\n"],"metadata":{"id":"rcUwbNEZvF5W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Read GIF and convert to base64\n","with open(output_gif_path, \"rb\") as gif_file:\n","    gif_base64 = base64.b64encode(gif_file.read()).decode(\"utf-8\")\n","\n","# Embed in HTML\n","html_code = f'''\n","<h3>Generated GIF:</h3>\n","<img src=\"data:image/gif;base64,{gif_base64}\" alt=\"Generated GIF\">\n","'''\n","\n","# Display HTML\n","display(HTML(html_code))"],"metadata":{"id":"nwwgjSnWvdnp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lLb_AVLevubS"},"execution_count":null,"outputs":[]}]}